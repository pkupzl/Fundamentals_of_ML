{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multiple linear regression tasks, the action function is mutiple regression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare a dataset $\\{ (\\bm{x}_{i},y_{i})\\},i=1,\\dots,m$, where $\\bm{x}_{i}=(x_{i1},\\dots,x_{id})^{\\top}\\in\\mathbb{R}^{d}$ and $y_{i}\\in\\mathbb{R}$.<br>\n",
    "In the training set, we prepare $m=100$ samples with feature dimension $d=2$. Then we create a matrix $X_{train}=(x_{1}^{T},\\dots,x_{m}^{T})^{T}\\in\\mathbb{R}^{m\\times d}$<br>\n",
    "We set the real parameters $w_{real}=(1,2)^{T} ,b=4$ for testing.<br>\n",
    "And $Y = X_{train}w_{real}+b+Noise$ is the labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        # 如果文件夹不存在，则创建它\n",
    "        os.makedirs(folder_path)\n",
    "        print(\"文件夹已创建\")\n",
    "    else:\n",
    "        print(\"文件夹已存在，不需要创建\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已创建\n"
     ]
    }
   ],
   "source": [
    "create_folder(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100, 1), (2, 1), (1, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dim = 2\n",
    "train_m = 100\n",
    "X_train = np.random.rand(train_m,feature_dim)#m*d\n",
    "w_real = np.array([[1], [2]])\n",
    "b = np.array([[4]])\n",
    "Y = X_train@w_real+ b + np.random.randn(train_m,1)*0.01\n",
    "X_train.shape, Y.shape, w_real.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deriving the optimal paramter $w$, we firstly definne the rules for vector derivative<br>\n",
    "if we have a scalar $F=F(\\bm{x})$ where the independent varible $\\bm{x}\\in\\mathbb{R}^{d}$, then the derivative formula of $F$ with respect to $\\bm{x}$ is as follows:<br>\n",
    "$$ \\frac{\\partial F}{\\partial \\bm{x}}= [\\frac{\\partial F}{\\partial x_{1}},\\dots,\\frac{\\partial F}{\\partial x_{d}}]^{T}\\in\\mathbb{R}^{d} $$\n",
    "if we have a vector $\\bm{F}=\\bm{F}(\\bm{x})=[F_{1}(\\bm{x}),\\dots,F_{1}(\\bm{x})]^{T}\\in\\mathbb{R}^{m}$ where the independent varible $\\bm{x}\\in\\mathbb{R}^{d}$, then the derivative formula of $\\bm{F}$ with respect to $\\bm{x}$ is as follows:<br>\n",
    "$$ \\frac{\\partial \\bm{F}}{\\partial \\bm{x}}= [\\frac{\\partial F_{1}}{\\partial \\bm{x}},\\dots,\\frac{\\partial F_{m}}{\\partial \\bm{x}}]\\in\\mathbb{R}^{d\\times m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can derive the optimal parameter $w$ for multiple linear regression.<br>\n",
    "We use the least square loss principle: the residual sum of squares (RSS) is minimized.<br>\n",
    "$$ RSS(\\bar{\\bm{w}})=||\\hat{\\bm{y}}-\\bm{y}||^{2}_{2}=||\\bm{y}-\\bar{\\bm{X}}\\bar{\\bm{w}}||^{2}_{2}$$\n",
    "$$ \\frac{\\partial RSS(\\bar{\\bm{w}})}{\\partial \\bar{\\bm{w}}}= \\frac{\\partial \\{ (\\bm{y}-\\bar{\\bm{X}}\\bar{\\bm{w}})^{T}(\\bm{y}-\\bar{\\bm{X}}\\bar{\\bm{w}})\\} }{\\partial \\bar{\\bm{w}}} = 2\\bar{\\bm{X}}^{T}(\\bar{\\bm{X}}\\bar{\\bm{w}}-\\bm{y}) $$\n",
    "Here, $\\bar{\\bm{w}}=(\\bm{w},b)\\in\\mathbb{R}^{d+1}$ represents the expanded vector , and $\\bar{\\bm{X}}\\in\\mathbb{R}^{m \\times (d+1) }$ is the expanded matrix with $1$ as the **last column**.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial RSS(\\bar{\\bm{w}})}{\\partial \\bar{\\bm{w}}}= 0 \\Rightarrow \\bar{\\bm{w}}=(\\bm{X}^{T} \\bm{X})^{-1}\\bm{X}^{T}\\bm{y} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bar = np.hstack((X_train,np.ones((m,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99906013],\n",
       "       [2.00311505],\n",
       "       [3.99771095]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (np.linalg.inv(X_bar.T@X_bar))@X_bar.T@Y\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this result we can see that the optimal parameter $\\bar{\\bm{w}}$ is very close to the real parameter $\\bar{\\bm{w}}_{real}=(w_{real},b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
